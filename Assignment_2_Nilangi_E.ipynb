{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOI/E082HPtsNRvxDDIJzTf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nilangi-ediri/Machine-Learning-/blob/main/Assignment_2_Nilangi_E.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tv_Vby1bIwNd",
        "outputId": "17ba13b7-b679-4270-cc67-35cf19baac88"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "solution of b: 1.7870065517754259\n",
            "sum of all dimensions of w solution: -0.2713847619329983\n",
            "test_accuracy %: 96.93128752501667\n"
          ]
        }
      ],
      "source": [
        "import cvxpy as cp\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "def load_data_from_csv(file_name):\n",
        "    data = pd.read_csv(file_name)\n",
        "    labels = data.iloc[:,0].values\n",
        "    labels = np.where(labels==0,-1,labels)\n",
        "    features = data.iloc[:,1:].values\n",
        "    return features, labels\n",
        "\n",
        "def svm_train_primal ( data_train , label_train , regularisation_para_C ):\n",
        "    m,n = data_train.shape\n",
        "\n",
        "    w=cp.Variable(n)\n",
        "    b=cp.Variable()\n",
        "    si=cp.Variable(m)\n",
        "    objective_function=cp.Minimize(0.5*cp.norm(w,2)**2+(regularisation_para_C/m)*cp.sum(si))\n",
        "    constraints=[cp.multiply(label_train,data_train@w+b)>=(1-si),si>=0]\n",
        "    optimization_problem=cp.Problem(objective_function,constraints)\n",
        "    optimization_problem.solve()\n",
        "\n",
        "    svm_model = {\n",
        "        \"w\":w.value,\n",
        "        \"b\":b.value,\n",
        "         }\n",
        "\n",
        "    return svm_model\n",
        "\n",
        "def svm_predict_primal ( data_test , label_test , svm_model ):\n",
        "    w=svm_model[\"w\"]\n",
        "    b=svm_model[\"b\"]\n",
        "    predictions = np.sign(data_test@w+b)\n",
        "    accuracy = np.mean(predictions==label_test)*100\n",
        "    return accuracy\n",
        "\n",
        "data_train, label_train = load_data_from_csv(\"/train.csv\")\n",
        "data_test, label_test = load_data_from_csv(\"/test.csv\")\n",
        "\n",
        "## Setting training data size to 4000 samples as instructed\n",
        "train_size = 4000\n",
        "data_train_subset = data_train[:train_size]\n",
        "label_train_subset = label_train[:train_size]\n",
        "\n",
        "data_validation_subset = data_train[train_size:]\n",
        "label_validation_subset = label_train[train_size:]\n",
        "\n",
        "svm_model = svm_train_primal ( data_train_subset , label_train_subset , 100 )\n",
        "test_accuracy = svm_predict_primal ( data_test , label_test , svm_model )\n",
        "w_primal = svm_model[\"w\"]\n",
        "b_primal = svm_model[\"b\"]\n",
        "print(\"solution of b:\", b_primal)\n",
        "print(\"sum of all dimensions of w solution:\", np.sum(w_primal))\n",
        "print(\"test_accuracy %:\", test_accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cvxpy as cp\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "def load_data_from_csv(file_name):\n",
        "    data = pd.read_csv(file_name)\n",
        "    labels = data.iloc[1:,0].values\n",
        "    labels = np.where(labels==0,-1,labels)\n",
        "    features = data.iloc[1:,1:].values\n",
        "    return features, labels\n",
        "\n",
        "def svm_train_primal ( data_train , label_train , regularisation_para_C ):\n",
        "    m,n = data_train.shape\n",
        "\n",
        "    w=cp.Variable(n)\n",
        "    b=cp.Variable()\n",
        "    si=cp.Variable(m)\n",
        "    objective_function=cp.Minimize(0.5*cp.norm(w,2)**2+(regularisation_para_C/m)*cp.sum(si))\n",
        "    constraints=[cp.multiply(label_train,data_train@w+b)>=(1-si),si>=0]\n",
        "    optimization_problem=cp.Problem(objective_function,constraints)\n",
        "    optimization_problem.solve()\n",
        "\n",
        "    svm_model = {\n",
        "        \"w\":w.value,\n",
        "        \"b\":b.value,\n",
        "         }\n",
        "\n",
        "    return svm_model\n",
        "\n",
        "def svm_predict_primal ( data_test , label_test , svm_model ):\n",
        "    w=svm_model[\"w\"]\n",
        "    b=svm_model[\"b\"]\n",
        "    predictions = np.sign(data_test@w+b)\n",
        "    accuracy = np.mean(predictions==label_test)*100\n",
        "    return accuracy\n",
        "\n",
        "data_train, label_train = load_data_from_csv(\"/content/train.csv\")\n",
        "data_test, label_test = load_data_from_csv(\"/content/test.csv\")\n",
        "\n",
        "## Setting training data size to 4000 samples as instructed\n",
        "train_size = 4000\n",
        "data_train_subset = data_train[:train_size]\n",
        "label_train_subset = label_train[:train_size]\n",
        "\n",
        "data_validation_subset = data_train[train_size:]\n",
        "label_validation_subset = label_train[train_size:]\n",
        "\n",
        "svm_model = svm_train_primal ( data_train_subset , label_train_subset , 100 )\n",
        "test_accuracy = svm_predict_primal ( data_test , label_test , svm_model )\n",
        "w_primal = svm_model[\"w\"]\n",
        "b_primal = svm_model[\"b\"]\n",
        "print(\"solution of b:\", b_primal)\n",
        "print(\"sum of all dimensions of w solution:\", np.sum(w_primal))\n",
        "print(\"test_accuracy %:\", test_accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-RDX55P_XGE0",
        "outputId": "41fb0b12-5c08-47ce-ce21-fa32af0eb557"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "solution of b: 1.7870065527010477\n",
            "sum of all dimensions of w solution: -0.2713847651065925\n",
            "test_accuracy %: 96.92923898531375\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cvxopt\n",
        "import cvxopt.solvers\n",
        "from cvxopt import matrix\n",
        "from cvxopt import solvers\n",
        "\n",
        "def svm_train_dual(data_train, label_train, regularisation_para_C):\n",
        "    m, n = data_train.shape\n",
        "\n",
        "    # Calculating the dot product of the data\n",
        "    dot_product = np.dot(data_train, data_train.T)\n",
        "\n",
        "    # Converting data to cvxopt matrices\n",
        "    P = matrix(np.outer(label_train, label_train) * dot_product)\n",
        "    q = matrix(-np.ones(m))\n",
        "\n",
        "    # Setting up the constraints:\n",
        "    G = matrix(np.vstack((-np.eye(m), np.eye(m))))\n",
        "    h = matrix(np.hstack((np.zeros(m), np.ones(m) * regularisation_para_C)))\n",
        "\n",
        "    A = matrix(label_train, (1, m), 'd')\n",
        "    b = matrix(0.0)\n",
        "\n",
        "    # Solving the quadratic problem\n",
        "    solution = solvers.qp(P, q, G, h, A, b)\n",
        "\n",
        "    alpha_value = np.ravel(solution['x'])\n",
        "\n",
        "    svm_model_dual = {\n",
        "        \"alpha\": alpha_value,\n",
        "    }\n",
        "\n",
        "    return svm_model_dual\n",
        "\n",
        "svm_model_dual = svm_train_dual ( data_train_subset , label_train_subset , 100 )\n",
        "\n",
        "print(\"alpha_values:\",svm_model_dual[\"alpha\"])\n",
        "\n",
        "print(\"sum of all dimensions of the optimal alpha solution:\", np.sum(svm_model_dual[\"alpha\"]))\n",
        "\n",
        "alpha = svm_model_dual[\"alpha\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WmhUF2nQJesB",
        "outputId": "88ed9e5e-7839-4773-e098-61d121429ace"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     pcost       dcost       gap    pres   dres\n",
            " 0: -3.7283e+04 -3.5345e+07  1e+08  1e+00  6e-11\n",
            " 1: -2.5207e+04 -1.2988e+07  2e+07  1e-01  5e-11\n",
            " 2: -1.4749e+04 -4.1672e+06  6e+06  4e-02  4e-11\n",
            " 3: -9.9947e+03 -1.7422e+06  2e+06  1e-02  4e-11\n",
            " 4: -9.2237e+03 -7.2994e+05  9e+05  4e-03  4e-11\n",
            " 5: -1.0924e+04 -2.4205e+05  2e+05  6e-04  4e-11\n",
            " 6: -1.2293e+04 -8.1876e+04  7e+04  2e-04  4e-11\n",
            " 7: -1.3188e+04 -6.5616e+04  5e+04  1e-04  4e-11\n",
            " 8: -1.3188e+04 -6.3708e+04  5e+04  7e-05  4e-11\n",
            " 9: -1.3834e+04 -5.2014e+04  4e+04  4e-05  4e-11\n",
            "10: -1.4714e+04 -4.1835e+04  3e+04  2e-05  5e-11\n",
            "11: -1.5405e+04 -3.7422e+04  2e+04  1e-05  5e-11\n",
            "12: -1.5732e+04 -3.4712e+04  2e+04  9e-06  5e-11\n",
            "13: -1.6325e+04 -3.0930e+04  1e+04  6e-06  5e-11\n",
            "14: -1.6652e+04 -2.8737e+04  1e+04  4e-06  5e-11\n",
            "15: -1.7029e+04 -2.6729e+04  1e+04  2e-06  6e-11\n",
            "16: -1.7492e+04 -2.4885e+04  7e+03  1e-06  6e-11\n",
            "17: -1.7812e+04 -2.3828e+04  6e+03  7e-07  6e-11\n",
            "18: -1.8341e+04 -2.2350e+04  4e+03  3e-07  7e-11\n",
            "19: -1.8453e+04 -2.1929e+04  3e+03  2e-07  7e-11\n",
            "20: -1.8765e+04 -2.1144e+04  2e+03  1e-07  7e-11\n",
            "21: -1.8885e+04 -2.0806e+04  2e+03  6e-08  7e-11\n",
            "22: -1.9195e+04 -2.0215e+04  1e+03  3e-08  7e-11\n",
            "23: -1.9313e+04 -1.9967e+04  7e+02  1e-08  8e-11\n",
            "24: -1.9417e+04 -1.9793e+04  4e+02  5e-09  8e-11\n",
            "25: -1.9454e+04 -1.9726e+04  3e+02  2e-09  8e-11\n",
            "26: -1.9543e+04 -1.9605e+04  6e+01  3e-10  9e-11\n",
            "27: -1.9559e+04 -1.9584e+04  2e+01  1e-10  9e-11\n",
            "28: -1.9563e+04 -1.9578e+04  1e+01  3e-11  9e-11\n",
            "29: -1.9569e+04 -1.9572e+04  3e+00  5e-12  9e-11\n",
            "30: -1.9570e+04 -1.9570e+04  1e-01  9e-13  1e-10\n",
            "31: -1.9570e+04 -1.9570e+04  1e-03  4e-13  1e-10\n",
            "Optimal solution found.\n",
            "alpha_values: [2.62460003e-08 2.66028004e-08 3.63858542e-08 ... 3.50277440e-08\n",
            " 2.28798801e-08 2.36201363e-08]\n",
            "sum of all dimensions of the optimal alpha solution: 19572.932569219818\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "regularisation_para_C = 100\n",
        "\n",
        "def calculate_w_b (alpha,data_train,label_train):\n",
        "    m,n = data_train.shape\n",
        "    w = np.sum(alpha[:, np.newaxis] * label_train[:, np.newaxis] * data_train, axis=0)\n",
        "    support_vector_indices = (alpha>1e-5) & (alpha<regularisation_para_C/m) #Here 1e-5 fixes the rounding error in Python - alpha>0\n",
        "    support_vectors = data_train[support_vector_indices]\n",
        "    support_labels = label_train[support_vector_indices]\n",
        "    b = np.mean(support_labels - np.dot(support_vectors, w))\n",
        "    return w,b\n",
        "\n",
        "w_dual,b_dual = calculate_w_b(alpha,data_train_subset,label_train_subset)\n",
        "\n",
        "print(\"solution of b from dual:\", b_dual)\n",
        "print(\"sum of all dimensions of w solution from dual:\", np.sum(w_dual))\n",
        "print(\"solution of w from dual:\", w_dual)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ndKPWieuTD-h",
        "outputId": "c643f37b-9a0d-4fc7-cedc-fe36cd5718a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "solution of b from dual: 2.9720025258306513\n",
            "sum of all dimensions of w solution from dual: -0.15719023146272093\n",
            "solution of w from dual: [ 9.45621118e-03 -1.70759366e-01  9.20691146e-02 -7.15859259e-02\n",
            "  1.21314351e-01 -1.23895206e-01 -2.31701574e-02 -9.99884004e-02\n",
            "  9.99544093e-02 -1.29327518e-02  2.03353070e-01  1.10539387e-01\n",
            "  1.28142333e-02  1.80748553e-01  3.32349909e-02 -1.32511566e-01\n",
            " -1.41050407e-01 -1.81981120e-02 -1.46128893e-01 -3.41279225e-02\n",
            "  6.61848270e-03  1.62974496e-01  1.08065881e-01 -8.06418838e-03\n",
            " -9.29391944e-03 -1.80520630e-02 -5.32170663e-02  1.82866164e-02\n",
            " -1.98241166e-01  2.27589737e-01 -1.19591687e-01 -5.02491848e-02\n",
            "  6.08133436e-02 -7.33519195e-02  1.76780681e-01 -9.36579414e-02\n",
            " -3.02762463e-02 -1.24022115e-01  1.52388544e-01 -5.27707821e-02\n",
            "  1.00933622e-02  8.75880859e-02 -1.18236883e-01  6.37163243e-02\n",
            "  4.91217995e-02 -6.28458130e-02  2.50574372e-01  4.64866384e-02\n",
            "  1.82992582e-01  1.97948871e-01 -1.16891327e-01 -1.96800887e-02\n",
            "  7.92332106e-02 -8.62838685e-02  2.51554174e-03 -1.35339958e-02\n",
            " -1.09495238e-01  1.68292243e-01 -1.07870498e-01  1.14604567e+00\n",
            "  3.11497550e-02 -9.78951275e-02  2.73954843e-02 -4.89842723e-02\n",
            "  1.08430439e-02 -1.00684907e-01 -6.26592717e-02 -2.93326794e-02\n",
            " -7.55371530e-02 -1.09416920e-01 -1.33806287e-01 -8.85810319e-02\n",
            " -1.45650908e-01  1.44105668e-01  1.09297858e-01  1.01765496e-01\n",
            " -5.61046707e-02 -1.72385895e-01  7.24159847e-02  2.13410846e-01\n",
            "  4.35516623e-02 -1.25171112e-02 -9.97313781e-02  8.82113699e-02\n",
            "  1.07696130e-01 -5.74644833e-02 -7.23871867e-02  1.26820343e-02\n",
            "  6.38783357e-02 -7.91760704e-01  1.32428519e-02  1.33852019e-01\n",
            "  2.95040723e-02 -3.92616735e-02 -4.27249904e-02 -6.65650981e-02\n",
            " -3.03830858e-02 -1.11059299e-01  4.89206473e-02 -1.39600959e-01\n",
            "  7.61495939e-02  9.89406559e-02 -5.67108233e-02 -1.49189751e-01\n",
            "  6.38529882e-02 -4.68298328e-02 -5.12263851e-02 -1.18713728e-01\n",
            " -9.37183767e-01 -1.26055611e-01  1.55063284e-01  3.32835607e-02\n",
            " -3.41800873e-02 -1.07085547e-02  5.50892261e-02  1.74718435e-01\n",
            " -9.37602536e-02 -9.70993721e-02 -3.98100658e-02  7.25163905e-02\n",
            "  2.36685325e-01 -1.52469559e-01  6.52780638e-02  1.53997447e-01\n",
            " -1.76575626e-01  7.15849785e-02  9.16052813e-02 -2.44953474e-02\n",
            "  7.71340426e-02 -1.21199300e-02  9.67567873e-02 -2.28704283e-02\n",
            " -4.61510008e-02  3.34533045e-02 -4.60083124e-02 -5.88110579e-02\n",
            "  4.25012241e-02  1.13759284e-01  9.61016317e-02 -3.32082079e-02\n",
            " -1.70855914e-03 -1.96156299e-01  4.99319461e-02  1.25008389e-01\n",
            "  6.34152692e-02  3.56071637e-02  8.93409790e-03  1.30374903e-02\n",
            "  8.36256343e-02 -3.19887334e-03  3.22064137e-04  5.57476410e-02\n",
            " -4.97824743e-03 -1.92736720e-01 -9.83062943e-02 -7.01349610e-01\n",
            "  1.20493097e-01  1.86978505e-01  8.94512940e-02 -8.68969294e-02\n",
            "  9.44899715e-02 -1.02853549e-01 -8.99881889e-02  5.41281602e-02\n",
            "  4.07431693e-02  2.23614792e-02  5.02899982e-02 -4.53569655e-02\n",
            " -8.73689979e-03 -2.14092755e-02 -1.32669774e-01  1.15592951e-01\n",
            "  7.23319669e-01 -4.04459987e-02  8.71207818e-02 -5.64053840e-02\n",
            "  1.43690642e-01  1.01490911e-01 -4.69084228e-02 -1.07704102e-02\n",
            " -1.74095170e-02 -7.37897307e-02 -3.08737924e-02  6.18096570e-02\n",
            " -1.92714549e-01 -1.84699146e-01 -1.09856944e-01  2.16305745e-02\n",
            "  7.55781408e-02  2.19551038e-01 -6.86194712e-02 -7.56110240e-03\n",
            "  7.66702060e-03  1.02870552e-01  1.05735338e-01 -4.49666623e-03\n",
            " -4.69618970e-02 -1.70929048e-02 -2.26241922e-01  4.00230936e-02]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def find_support_vectors_primal(w,b,data_train, label_train, epsilon):\n",
        "   decision_value = np.dot(data_train,w) + b\n",
        "   decision_margin = np.abs(label_train * decision_value -1) #This condition ensures points lie very close to the margin\n",
        "   support_vector_indices = np.where(decision_margin < epsilon)\n",
        "   return support_vector_indices, data_train[support_vector_indices], label_train[support_vector_indices]\n",
        "\n",
        "##epsilon can be adjusted to reduce error margin when calculating support vectors\n",
        "support_vector_indices_primal, support_vectors_primal, support_labels_primal = find_support_vectors_primal(w_primal,b_primal,data_train_subset,label_train_subset,epsilon=1e-10)\n",
        "print(\"Total number of support vectors from primal:\", len(support_vectors_primal))\n",
        "print(\"Support vector indices from primal:\",support_vector_indices_primal)\n",
        "print(\"Support vectors from primal:\",support_vectors_primal)\n",
        "print(\"Support labels from primal:\",support_labels_primal)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XSez_7iSazhI",
        "outputId": "a7c546d0-36e3-4a83-f9f5-533173af4c95"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of support vectors from primal: 22\n",
            "Support vector indices from primal: (array([  15,  238,  546,  708,  795,  820,  842,  988, 1122, 1492, 1538,\n",
            "       1591, 1626, 1779, 1824, 1889, 2144, 2644, 2750, 3283, 3739, 3868]),)\n",
            "Support vectors from primal: [[ 1.05 -1.79  0.9  ...  0.39  0.6  -1.66]\n",
            " [ 0.38  2.13 -0.66 ...  0.21  2.36  0.49]\n",
            " [-0.18 -0.01 -2.21 ... -0.28 -0.37 -0.69]\n",
            " ...\n",
            " [-0.02  1.19  0.96 ...  2.27  0.22  0.82]\n",
            " [ 0.53  1.21 -0.08 ...  1.72 -0.49 -0.29]\n",
            " [ 1.24  0.29 -0.36 ... -0.67  1.79 -1.82]]\n",
            "Support labels from primal: [ 1. -1. -1. -1. -1.  1. -1. -1.  1. -1.  1. -1.  1. -1. -1. -1. -1.  1.\n",
            "  1. -1. -1.  1.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "regularisation_para_C = 100\n",
        "def find_support_vectors_dual(alpha,data_train,label_train, epsilon):\n",
        "    m,n = data_train.shape\n",
        "    support_vector_indices =np.where((alpha>epsilon) & (alpha<regularisation_para_C/m)) #Here epsilon fixes the rounding error in Python - alpha>0\n",
        "    support_vectors = data_train[support_vector_indices]\n",
        "    support_labels = label_train[support_vector_indices]\n",
        "\n",
        "    return support_vector_indices, data_train[support_vector_indices], label_train[support_vector_indices]\n",
        "\n",
        "\n",
        "support_vector_indices_dual, support_vectors_dual, support_labels_dual = find_support_vectors_dual(alpha,data_train_subset,label_train_subset,epsilon=1e-6)\n",
        "print(\"Total number of support vectors from dual:\", len(support_vectors_dual))\n",
        "print(\"support vector indices from dual:\",support_vector_indices_dual)\n",
        "print(\"support vectors from dual:\",support_vectors_dual)\n",
        "print(\"support labels from dual:\",support_labels_dual)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hg5STN3MheuU",
        "outputId": "566f9016-a766-4679-e419-b18565edf611"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of support vectors from dual: 21\n",
            "support vector indices from dual: (array([  28,  155,  167,  328,  458,  594,  605,  707,  820,  992, 1178,\n",
            "       1756, 1858, 1954, 2517, 2690, 2727, 3330, 3682, 3915, 3968]),)\n",
            "support vectors from dual: [[ 0.41 -0.19  0.88 ... -1.56  0.48 -0.23]\n",
            " [-1.4  -0.55  0.17 ... -1.57  0.11  1.29]\n",
            " [ 0.26  0.15 -1.63 ...  1.01  1.43  1.78]\n",
            " ...\n",
            " [-0.02 -0.04 -0.29 ... -0.24 -0.83  1.04]\n",
            " [ 0.15 -0.74  1.07 ...  0.51 -0.69 -0.36]\n",
            " [ 0.79  1.01  1.2  ...  0.85 -0.97  0.98]]\n",
            "support labels from dual: [ 1. -1.  1.  1.  1.  1.  1. -1.  1.  1. -1.  1.  1.  1.  1. -1. -1.  1.\n",
            " -1. -1.  1.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def validate_svm(data_train,label_train,data_validation,label_validation,C_values):\n",
        "  validation_accuracies = []\n",
        "  for C in C_values:\n",
        "    svm_model = svm_train_primal(data_train, label_train, C)\n",
        "    validation_accuracy = svm_predict_primal(data_validation, label_validation, svm_model)\n",
        "    validation_accuracies.append(validation_accuracy)\n",
        "    print(f'Validation accuracy for C = {C} : {validation_accuracy:.2f}%')\n",
        "  return validation_accuracies\n",
        "C_values =[2**i for i in range(-10,11,2)]\n",
        "validation_accuracies = validate_svm(data_train_subset,label_train_subset,data_validation_subset,label_validation_subset,C_values)\n",
        "best_C_index = np.argmax(validation_accuracies)\n",
        "best_C = C_values[best_C_index]\n",
        "print(f'Best C value: {best_C}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0bfyEOjHtLN9",
        "outputId": "1ebf1e93-59b6-41f4-b245-b74771533fa3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation accuracy for C = 0.0009765625 : 49.10%\n",
            "Validation accuracy for C = 0.00390625 : 49.10%\n",
            "Validation accuracy for C = 0.015625 : 49.10%\n",
            "Validation accuracy for C = 0.0625 : 92.49%\n",
            "Validation accuracy for C = 0.25 : 96.22%\n",
            "Validation accuracy for C = 1 : 97.18%\n",
            "Validation accuracy for C = 4 : 97.47%\n",
            "Validation accuracy for C = 16 : 97.40%\n",
            "Validation accuracy for C = 64 : 97.04%\n",
            "Validation accuracy for C = 256 : 96.51%\n",
            "Validation accuracy for C = 1024 : 96.44%\n",
            "Best C value: 4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "C_values =[i for i in range(1,16)]\n",
        "validation_accuracies = validate_svm(data_train_subset,label_train_subset,data_validation_subset,label_validation_subset,C_values)\n",
        "best_C_index = np.argmax(validation_accuracies)\n",
        "best_C = C_values[best_C_index]\n",
        "print(f'Best C value: {best_C}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OPeUEn3fx_DN",
        "outputId": "129ac9ab-e3ea-43c1-e59e-0977ace7e8c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation accuracy for C = 1 : 97.18%\n",
            "Validation accuracy for C = 2 : 97.35%\n",
            "Validation accuracy for C = 3 : 97.24%\n",
            "Validation accuracy for C = 4 : 97.47%\n",
            "Validation accuracy for C = 5 : 97.49%\n",
            "Validation accuracy for C = 6 : 97.53%\n",
            "Validation accuracy for C = 7 : 97.44%\n",
            "Validation accuracy for C = 8 : 97.51%\n",
            "Validation accuracy for C = 9 : 97.53%\n",
            "Validation accuracy for C = 10 : 97.49%\n",
            "Validation accuracy for C = 11 : 97.53%\n",
            "Validation accuracy for C = 12 : 97.51%\n",
            "Validation accuracy for C = 13 : 97.49%\n",
            "Validation accuracy for C = 14 : 97.49%\n",
            "Validation accuracy for C = 15 : 97.47%\n",
            "Best C value: 6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import LinearSVC\n",
        "svm_model_sk_learn = LinearSVC(C=best_C,dual=\"auto\")\n",
        "svm_model_sk_learn.fit(data_train_subset, label_train_subset)#training the model\n",
        "predictions_sk_learn = svm_model_sk_learn.predict(data_test)\n",
        "accuracy = np.mean(predictions_sk_learn==label_test)*100\n",
        "print(\"test_accuracy %:\", test_accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FdI1cBauy2S-",
        "outputId": "43a386d7-11da-470d-df1c-58e76955fad4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test_accuracy %: 96.93128752501667\n"
          ]
        }
      ]
    }
  ]
}